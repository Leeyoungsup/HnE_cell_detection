{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f827039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import yaml\n",
    "from torch.utils import data\n",
    "# 개별 json 라벨 파일을 이용해 학습 데이터 리스트 생성\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from nets import nn\n",
    "from utils import util\n",
    "from utils.dataset import Dataset\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.model_selection import train_test_split  # sklearn 사용\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 파라미터 및 데이터 경로 설정\n",
    "with open('utils/args.yaml', errors='ignore') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "label_dir = '../../data/HnE_cell_detect/total_data/labels/'\n",
    "image_dir = '../../data/HnE_cell_detect/total_data/images/'\n",
    "\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, '*.json')))\n",
    "filenames = []\n",
    "labels = []\n",
    "for label_file in label_files:\n",
    "    with open(label_file) as f:\n",
    "        data1 = json.load(f)\n",
    "    img_path = os.path.join(image_dir, data1['file_name'])\n",
    "    if os.path.exists(img_path):\n",
    "        filenames.append(img_path)\n",
    "        temp_labels = []\n",
    "        for i in range(len(data1[\"cordinates\"])):\n",
    "            if data1[\"cordinates\"][i][3] >50 or data1[\"cordinates\"][i][4]>50:\n",
    "                continue\n",
    "            temp_labels.append(data1[\"cordinates\"][i])\n",
    "        labels.append(temp_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(data.Dataset):\n",
    "    def __init__(self, filenames, input_size, params, augment, labels=None, image_infos=None):\n",
    "        self.params = params\n",
    "        self.mosaic = augment\n",
    "        self.augment = augment\n",
    "        self.input_size = input_size\n",
    "        if labels is not None:\n",
    "            self.labels = labels\n",
    "            self.filenames = filenames\n",
    "            self.n = len(self.filenames)\n",
    "            self.image_infos = image_infos if image_infos is not None else [None]*len(filenames)\n",
    "        else:\n",
    "            loaded = self.load_label(filenames)\n",
    "            self.labels = list(loaded.values())\n",
    "            self.filenames = list(loaded.keys())\n",
    "            self.n = len(self.filenames)\n",
    "            self.image_infos = [None]*self.n\n",
    "        self.indices = range(self.n)\n",
    "        self.albumentations = Albumentations()\n",
    "    def __len__(self):\n",
    "        return self.n*5\n",
    "    def __getitem__(self, index):\n",
    "        index= index % self.n\n",
    "        index = self.indices[index]\n",
    "        temp_label = copy.deepcopy(self.labels[index])\n",
    "        \n",
    "        image,crop_index=self.load_image(index)\n",
    "        \n",
    "        crop_y, crop_x = crop_index\n",
    "        label=[]\n",
    "        #y,x,h,w, to x_center,y_center,w,h\n",
    "        for i in range(len(temp_label)):\n",
    "            x = temp_label[i][2]\n",
    "            y = temp_label[i][1]\n",
    "            w = temp_label[i][4]\n",
    "            h = temp_label[i][3]\n",
    "            if x >= crop_x and y >= crop_y and x <= crop_x + self.input_size and y <= crop_y + self.input_size:\n",
    "                temp_label[i][1] = (x+w/2 - crop_x)/ self.input_size\n",
    "                temp_label[i][2] = (y+h/2 - crop_y)/ self.input_size\n",
    "                temp_label[i][3] = (w) / self.input_size\n",
    "                temp_label[i][4] = (h) / self.input_size\n",
    "                label.append(temp_label[i])\n",
    "\n",
    "        cls=[]\n",
    "        box=[]\n",
    "        for i in range(len(label)):\n",
    "            cls.append(label[i][0]-1)\n",
    "            box.append(label[i][1:5])\n",
    "        cls=np.array(cls)\n",
    "        box=np.array(box)\n",
    "        nl = len(box)\n",
    "        if self.augment:\n",
    "            nl = len(box)  # update after albumentations\n",
    "\n",
    "            # Flip up-down\n",
    "            if random.random() < self.params['flip_ud']:\n",
    "                image = np.flipud(image).copy()\n",
    "                if nl:\n",
    "                    box[:, 1] = 1 - box[:, 1]\n",
    "            # Flip left-right\n",
    "            if random.random() < self.params['flip_lr']:\n",
    "                image = np.fliplr(image).copy()\n",
    "                if nl:\n",
    "                    box[:, 0] = 1 - box[:, 0]\n",
    "\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image),torch.from_numpy(cls), torch.from_numpy(box), torch.zeros(nl)\n",
    "\n",
    "    def load_image(self, i):\n",
    "        image = cv2.imread(self.filenames[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB 변환\n",
    "        h, w = image.shape[:2]\n",
    "        r = self.input_size / min(h, w)\n",
    "        \n",
    "        # 이미지가 input_size보다 큰 경우 (r < 1) -> 랜덤 크롭\n",
    "        if r < 1:\n",
    "            # 안전하게 크롭 범위 계산\n",
    "            max_h = max(0, h - self.input_size)\n",
    "            max_w = max(0, w - self.input_size)\n",
    "            h1 = random.randint(0, max_h) if max_h > 0 else 0\n",
    "            w1 = random.randint(0, max_w) if max_w > 0 else 0\n",
    "            image = image[h1:h1 + self.input_size, w1:w1 + self.input_size]\n",
    "        else:\n",
    "            # 이미지가 input_size보다 작거나 같은 경우 (r >= 1) -> 패딩\n",
    "            h1 = 0\n",
    "            w1 = 0\n",
    "            pad_image = np.ones((self.input_size, self.input_size, 3), dtype=np.uint8)*255\n",
    "            pad_image[:min(h,self.input_size), :min(w,self.input_size), :] = image[:min(h,self.input_size), :min(w,self.input_size), :]\n",
    "            image = pad_image\n",
    "        return image, (h1, w1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Albumentations:\n",
    "    def __init__(self):\n",
    "        self.transform = None\n",
    "        try:\n",
    "            import albumentations\n",
    "\n",
    "            transforms = [albumentations.Blur(p=0.01),\n",
    "                          albumentations.CLAHE(p=0.01),\n",
    "                          albumentations.ToGray(p=0.01),\n",
    "                          albumentations.MedianBlur(p=0.01)]\n",
    "            self.transform = albumentations.Compose(transforms,\n",
    "                                                    albumentations.BboxParams('yolo', ['class_labels']))\n",
    "\n",
    "        except ImportError:  # package not installed, skip\n",
    "            pass\n",
    "\n",
    "    def __call__(self, image, box, cls):\n",
    "        if self.transform:\n",
    "            x = self.transform(image=image,\n",
    "                               bboxes=box,\n",
    "                               class_labels=cls)\n",
    "            image = x['image']\n",
    "            box = np.array(x['bboxes'])\n",
    "            cls = np.array(x['class_labels'])\n",
    "        return image, box, cls\n",
    "\n",
    "split=[0.9, 0.1]\n",
    "x_train,x_val,y_train,y_val=train_test_split(filenames,labels,test_size=0.1,random_state=42,shuffle=True)\n",
    "train_dataset=custom_dataset(x_train,512, params, augment=True, labels=y_train)\n",
    "val_dataset=custom_dataset(x_val,512, params, augment=False, labels=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872981f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn1(batch):\n",
    "    samples, cls, box, indices = zip(*batch)\n",
    "\n",
    "    cls = torch.cat(cls, dim=0)\n",
    "    box = torch.cat(box, dim=0)\n",
    "\n",
    "    new_indices = list(indices)\n",
    "    for i in range(len(indices)):\n",
    "        new_indices[i] += i * box.size(0)  # 각 인덱스에 배치 내 샘플 수를 곱함\n",
    "    indices = torch.cat(new_indices, dim=0)\n",
    "\n",
    "    targets = {'cls': cls,\n",
    "                'box': box,\n",
    "                'idx': indices}\n",
    "    return torch.stack(samples, dim=0), targets\n",
    "\n",
    "\n",
    "# 모델 및 파라미터 준비\n",
    "model = nn.yolo_v11_m(len(params['names'])).to(device)\n",
    "optimizer = torch.optim.SGD(util.set_params(model, params['weight_decay']),\n",
    "                            params['min_lr'], params['momentum'], nesterov=True)\n",
    "criterion = util.ComputeLoss(model, params)\n",
    "\n",
    "# 데이터셋 및 데이터로드 (안전한 함수 사용)\n",
    "batch_size = 4\n",
    "# 안전하게 데이터로더 생성하는 함수\n",
    "def create_safe_loader(dataset, batch_size, is_train=True):\n",
    "    \"\"\"\n",
    "    배치 크기에 맞게 데이터셋을 조정하여 안전하게 데이터로더를 생성하는 함수\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    # 배치 크기가 데이터셋 크기보다 큰 경우 배치 크기 조정\n",
    "    if dataset_size < batch_size:\n",
    "        print(f\"경고: 데이터셋 크기({dataset_size})가 배치 크기({batch_size})보다 작습니다. 배치 크기를 {dataset_size}로 조정합니다.\")\n",
    "        actual_batch_size = max(1, dataset_size)\n",
    "    else:\n",
    "        actual_batch_size = batch_size\n",
    "    \n",
    "    # 데이터셋이 배치 크기로 나누어 떨어지는지 확인\n",
    "    if dataset_size % actual_batch_size != 0:\n",
    "        print(f\"참고: 데이터셋 크기({dataset_size})가 배치 크기({actual_batch_size})로 나누어 떨어지지 않습니다.\")\n",
    "        print(f\"마지막 배치는 {dataset_size % actual_batch_size}개의 샘플을 포함합니다.\")\n",
    "    \n",
    "    # 데이터로더 생성\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=actual_batch_size, \n",
    "        shuffle=is_train,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn1,\n",
    "        drop_last=(not is_train)  # 훈련 시에는 마지막 배치 유지, 검증 시에는 마지막 배치 제외\n",
    "    )\n",
    "    \n",
    "    return loader, actual_batch_size\n",
    "# 안전하게 데이터로더 생성\n",
    "loader, train_batch_size = create_safe_loader(train_dataset, batch_size, is_train=True)\n",
    "val_loader, val_batch_size = create_safe_loader(val_dataset, 1, is_train=False)\n",
    "\n",
    "print(f\"최종 훈련 배치 크기: {train_batch_size}\")\n",
    "print(f\"최종 검증 배치 크기: {val_batch_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader를 사용한 배치 단위 시각화\n",
    "def visualize_val_loader_samples(val_loader, num_batches=4):\n",
    "    \"\"\"\n",
    "    val_loader에서 배치 단위로 샘플을 가져와서 시각화\n",
    "    \"\"\"\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "    class_names = {0:\"Neutrophil\", 1:\"Epithelial\", 2:\"Lymphocyte\", \n",
    "                   3:\"Plasma\", 4:\"Eosinophil\", 5:\"Connective tissue\"}\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    batch_count = 0\n",
    "    for batch_idx, (images, targets) in enumerate(val_loader):\n",
    "        if batch_count >= num_batches:\n",
    "            break\n",
    "            \n",
    "        # 첫 번째 이미지만 시각화 (배치 크기가 1이므로)\n",
    "        image_tensor = images[0]  # (C, H, W)\n",
    "        cls_tensor = targets['cls']\n",
    "        box_tensor = targets['box']\n",
    "        \n",
    "        # 텐서를 numpy로 변환 및 이미지 복원\n",
    "        image = image_tensor.permute(1, 2, 0).numpy()  # (C, H, W) -> (H, W, C)\n",
    "       # 0-1 범위로 클리핑\n",
    "        \n",
    "        cls = cls_tensor.numpy() if len(cls_tensor) > 0 else []\n",
    "        boxes = box_tensor.numpy() if len(box_tensor) > 0 else []\n",
    "        \n",
    "        ax = axes[batch_count]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f'Val Loader Batch {batch_idx}', fontsize=12)\n",
    "        \n",
    "        # 바운딩 박스 그리기 (YOLO 형식: 정규화된 중심점 좌표)\n",
    "        class_counts = {}\n",
    "        h_img, w_img = image.shape[:2]\n",
    "        \n",
    "        for i, (class_id, box) in enumerate(zip(cls, boxes)):\n",
    "            if len(box) < 4:\n",
    "                continue\n",
    "                \n",
    "            # YOLO 형식: [y_center, x_center, height, width] (정규화됨)\n",
    "            x_center_norm, y_center_norm, w_norm, h_norm = box\n",
    "            \n",
    "            # 정규화된 좌표를 절대 좌표로 변환\n",
    "            x_center = x_center_norm * w_img\n",
    "            y_center = y_center_norm * h_img\n",
    "            w_abs = w_norm * w_img\n",
    "            h_abs = h_norm * h_img\n",
    "            \n",
    "            # 좌상단 좌표 계산\n",
    "            x_abs = x_center - w_abs / 2\n",
    "            y_abs = y_center - h_abs / 2\n",
    "            \n",
    "            # 클래스별 개수 세기\n",
    "            class_name = class_names.get(int(class_id), f\"Class_{int(class_id)}\")\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "            \n",
    "            # 바운딩 박스 생성\n",
    "            rect = patches.Rectangle((x_abs, y_abs), w_abs, h_abs, \n",
    "                                   linewidth=2, \n",
    "                                   edgecolor=colors[int(class_id)], \n",
    "                                   facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # 클래스 라벨 텍스트 추가\n",
    "            \n",
    "            # 중심점 표시 (YOLO 특징)\n",
    "            ax.plot(x_center, y_center, 'o', color=colors[int(class_id)], markersize=3)\n",
    "        \n",
    "        # 클래스별 개수 정보 표시\n",
    "        info_text = '\\n'.join([f'{name}: {count}' for name, count in class_counts.items()])\n",
    "        if info_text:\n",
    "            ax.text(0.02, 0.98, info_text, \n",
    "                   transform=ax.transAxes, \n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightblue', alpha=0.8),\n",
    "                   fontsize=10)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        batch_count += 1\n",
    "    \n",
    "    # 빈 서브플롯 숨기기\n",
    "    for idx in range(batch_count, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n🖼️  Val Loader 배치 샘플 시각화 (DataLoader에서 직접 가져온 데이터)\")\n",
    "visualize_val_loader_samples(val_loader, num_batches=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ground_truth_and_prediction_separately(model, dataset, idx=0, conf_threshold=0.2, iou_threshold=0.3, epoch=None, save_dir=None):\n",
    "    \"\"\"실제 라벨과 예측 라벨을 subplot으로 좌우에 표시하는 함수\"\"\"\n",
    "    if len(dataset) <= idx:\n",
    "        print(f\"경고: 데이터셋이 비어 있거나 idx {idx}가 데이터셋 크기({len(dataset)})보다 큽니다.\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    img, cls, box, _ = dataset[idx]\n",
    "    \n",
    "    # 하나의 figure에 2개의 subplot 생성 (1행 2열)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    img = img.cpu()/255.\n",
    "    # Subplot 1: Ground Truth (실제 라벨)\n",
    "    ax1.imshow(img.permute(1, 2, 0).cpu().numpy())\n",
    "    class_names = {\n",
    "            0: \"Neutrophil\",\n",
    "            1: \"Epithelial\",\n",
    "            2: \"Lymphocyte\",\n",
    "            3: \"Plasma\",\n",
    "            4: \"Eosinophil\",\n",
    "            5: \"Connective tissue\"\n",
    "        }\n",
    "    for i in range(len(cls)):\n",
    "        class_id = cls[i].item()\n",
    "        x_center, y_center, w, h = box[i].tolist()\n",
    "        \n",
    "        x = (x_center - w/2) * img.shape[2]\n",
    "        y = (y_center - h/2) * img.shape[1]\n",
    "        w_box = w * img.shape[2]\n",
    "        h_box = h * img.shape[1]\n",
    "        if class_id == 0: #Neutrophil\n",
    "            color = 'orange'\n",
    "        elif class_id == 1: #Epithelial\n",
    "            color = 'green'\n",
    "        elif class_id == 2: #Lymphocyte\n",
    "            color = 'red'\n",
    "        elif class_id == 3: #Plasma\n",
    "            color = 'skyblue'\n",
    "        elif class_id == 4: #Eosinophil\n",
    "            color = 'blue'\n",
    "        elif class_id == 5: #Connective tissue\n",
    "            color = 'yellow'\n",
    "        # 중심점 표시\n",
    "        # 중심점 좌표 계산\n",
    "        center_x = int(x + w_box / 2)\n",
    "        center_y = int(y + h_box / 2)\n",
    "\n",
    "        ax1.scatter(center_x, center_y, facecolors='none',  s=20, marker='o', edgecolors=color, linewidths=1)\n",
    "\n",
    "    gt_title = f'Ground Truth '\n",
    "    if epoch is not None:\n",
    "        gt_title += f' - Epoch {epoch}'\n",
    "    ax1.set_title(gt_title, fontsize=16, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Subplot 2: Model Prediction (예측 라벨)\n",
    "    ax2.imshow(img.permute(1, 2, 0).cpu().numpy())\n",
    "    \n",
    "    prediction_count = 0\n",
    "    with torch.no_grad():\n",
    "        img_input = img.unsqueeze(0).to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            pred = model(img_input)\n",
    "\n",
    "        # NMS 적용\n",
    "        results = util.non_max_suppression(pred, confidence_threshold=conf_threshold, iou_threshold=iou_threshold)\n",
    "        if len(results[0]) > 0:\n",
    "            for *xyxy, conf, cls_id in results[0]:\n",
    "                x1, y1, x2, y2 = xyxy\n",
    "                x1, y1, x2, y2 = x1.item(), y1.item(), x2.item(), y2.item()\n",
    "                w_pred = x2 - x1\n",
    "                h_pred = y2 - y1\n",
    "\n",
    "                if cls_id.item() == 0: #Neutrophil\n",
    "                    color = 'orange'\n",
    "                elif cls_id.item() == 1: #Epithelial\n",
    "                    color = 'yellow'\n",
    "                elif cls_id.item() == 2: #Lymphocyte\n",
    "                    color = 'blue'\n",
    "                elif cls_id.item() == 3: #Plasma\n",
    "                    color = 'skyblue'\n",
    "                elif cls_id.item() == 4: #Eosinophil\n",
    "                    color = 'purple'\n",
    "                elif cls_id.item() == 5: #Connective tissue\n",
    "                    color = 'orange'\n",
    "                # 중심점 표시\n",
    "                center_x = (x1 + x2)//2\n",
    "                center_y = (y1 + y2)//2\n",
    "                ax2.scatter(center_x, center_y, facecolors='none',  s=20, marker='o', edgecolors=color, linewidths=1)\n",
    "\n",
    "                prediction_count += 1\n",
    "        \n",
    "        if prediction_count == 0:\n",
    "            ax2.text(img.shape[2]//2, img.shape[1]//2, 'No Predictions', \n",
    "                     fontsize=20, color='white', ha='center', va='center',\n",
    "                     bbox=dict(facecolor='red', alpha=0.8, pad=10))\n",
    "    \n",
    "    pred_title = f'Model Prediction - {prediction_count} detections'\n",
    "    if epoch is not None:\n",
    "        pred_title += f' - Epoch {epoch}'\n",
    "    ax2.set_title(pred_title, fontsize=16, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # 전체 figure 제목 설정\n",
    "    if epoch is not None:\n",
    "        fig.suptitle(f'Validation Comparison - Epoch {epoch}, Sample {idx+1}', \n",
    "                     fontsize=18, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # 범례 추가\n",
    "    legend_elements = [\n",
    "        patches.Patch(color='orange', label='Neutrophil'),\n",
    "        patches.Patch(color='green', label='Epithelial'),\n",
    "        patches.Patch(color='red', label='Lymphocyte'),\n",
    "        patches.Patch(color='skyblue', label='Plasma'),\n",
    "        patches.Patch(color='purple', label='Eosinophil'),\n",
    "        patches.Patch(color='yellow', label='Connective tissue'),\n",
    "    ]\n",
    "    fig.legend(handles=legend_elements, loc='lower center', ncol=3, \n",
    "               bbox_to_anchor=(0.5, 0.02), fontsize=12)\n",
    "    \n",
    "    # 레이아웃 조정\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15, top=0.85)\n",
    "    \n",
    "    # 저장\n",
    "    if save_dir and epoch:\n",
    "        save_path = os.path.join(save_dir, f'validation_comparison_epoch_{epoch}.png')\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"✅ 비교 이미지 저장: {save_path}\")\n",
    "    \n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3682b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.valid import compute_validation_metrics, compute_validation_metrics_with_kappa, get_kappa_interpretation\n",
    "\n",
    "from utils.valid import plot_training_progress\n",
    "\n",
    "\n",
    "# main.py의 train 함수를 참조한 개선된 학습 루프\n",
    "train_losses = []\n",
    "val_maps = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_map50s = []\n",
    "val_kappas = []  # Cohen's Kappa 추가\n",
    "epochs = 10000\n",
    "\n",
    "# 체크포인트 저장을 위한 디렉토리 생성\n",
    "save_dir = '../../model/HnE_cell_detection/yolov11/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "#체크포인트 불러오기 \n",
    "checkpoint_path = os.path.join(save_dir, 'best_model.pt')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device,weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "# main.py 스타일의 설정들\n",
    "best_map = 0\n",
    "accumulate = max(round(64 / batch_size), 1)  # gradient accumulation steps\n",
    "amp_scale = torch.amp.GradScaler()  # mixed precision scaler\n",
    "\n",
    "print(f\"Gradient accumulation steps: {accumulate}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 훈련\n",
    "    model.train()\n",
    "    \n",
    "    # main.py 스타일의 평균 손실 추적\n",
    "    avg_box_loss = util.AverageMeter()\n",
    "    avg_cls_loss = util.AverageMeter()\n",
    "    avg_dfl_loss = util.AverageMeter()\n",
    "    \n",
    "    train_pbar = tqdm.tqdm(enumerate(loader), total=len(loader), desc=f'Epoch {epoch+1}/{epochs} Training')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i, (images, targets) in train_pbar:\n",
    "        step = i + len(loader) * epoch\n",
    "        images = images.to(device).float() / 255.\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(images)\n",
    "            loss_box, loss_cls, loss_dfl = criterion(outputs, targets)\n",
    "        \n",
    "        # 평균 손실 업데이트\n",
    "        avg_box_loss.update(loss_box.item(), images.size(0))\n",
    "        avg_cls_loss.update(loss_cls.item(), images.size(0))\n",
    "        avg_dfl_loss.update(loss_dfl.item(), images.size(0))\n",
    "        \n",
    "        # Loss scaling for gradient accumulation\n",
    "        loss_box *= batch_size  # loss scaled by batch_size\n",
    "        loss_cls *= batch_size  # loss scaled by batch_size  \n",
    "        loss_dfl *= batch_size  # loss scaled by batch_size\n",
    "        \n",
    "        total_loss = loss_box + loss_cls + loss_dfl\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        amp_scale.scale(total_loss).backward()\n",
    "        \n",
    "        # Gradient accumulation 및 optimization\n",
    "        if step % accumulate == 0:\n",
    "            # Gradient clipping 및 optimization\n",
    "            amp_scale.step(optimizer)\n",
    "            amp_scale.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # GPU 메모리 동기화\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # 진행률 표시 업데이트 (main.py 스타일)\n",
    "        memory = f'{torch.cuda.memory_reserved() / 1E9:.4g}G'\n",
    "        s = f'Memory: {memory} | Box: {avg_box_loss.avg:.3f} | Cls: {avg_cls_loss.avg:.3f} | DFL: {avg_dfl_loss.avg:.3f}'\n",
    "        train_pbar.set_description(f'Epoch {epoch+1}/{epochs} | {s}')\n",
    "    \n",
    "    # 에폭 평균 손실 계산\n",
    "    avg_train_loss = avg_box_loss.avg + avg_cls_loss.avg + avg_dfl_loss.avg\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # 검증 (Cohen's Kappa 포함)\n",
    "    precision, recall, map50, mean_ap, kappa = compute_validation_metrics_with_kappa(\n",
    "        model, val_loader, device, params\n",
    "    )\n",
    "    val_maps.append(mean_ap)\n",
    "    val_precisions.append(precision)\n",
    "    val_recalls.append(recall)\n",
    "    val_map50s.append(map50)\n",
    "    val_kappas.append(kappa)\n",
    "    \n",
    "    # F1-score 계산\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # 결과 출력 (Cohen's Kappa 포함)\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs} Results:\")\n",
    "    print(f\"  Train Loss - Box: {avg_box_loss.avg:.4f}, Cls: {avg_cls_loss.avg:.4f}, DFL: {avg_dfl_loss.avg:.4f}, Total: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n",
    "    print(f\"  mAP@0.5: {map50:.4f}, mAP@0.5:0.95: {mean_ap:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {kappa:.4f} ({get_kappa_interpretation(kappa)})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # 베스트 모델 저장 (mAP 기준)\n",
    "    if mean_ap > best_map:\n",
    "        best_map = mean_ap\n",
    "        save_checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'amp_scale_state_dict': amp_scale.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'box_loss': avg_box_loss.avg,\n",
    "            'cls_loss': avg_cls_loss.avg,\n",
    "            'dfl_loss': avg_dfl_loss.avg,\n",
    "            'map': mean_ap,\n",
    "            'map50': map50,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'kappa': kappa,\n",
    "            'params': params\n",
    "        }\n",
    "        torch.save(save_checkpoint, os.path.join(save_dir, 'best_model.pt'))\n",
    "        print(f\"🎉 새로운 베스트 모델 저장! mAP: {mean_ap:.4f}, Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    # 최신 모델도 저장 (main.py 스타일)\n",
    "    last_checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'amp_scale_state_dict': amp_scale.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'box_loss': avg_box_loss.avg,\n",
    "        'cls_loss': avg_cls_loss.avg,\n",
    "        'dfl_loss': avg_dfl_loss.avg,\n",
    "        'map': mean_ap,\n",
    "        'map50': map50,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'kappa': kappa,\n",
    "        'params': params\n",
    "    }\n",
    "    torch.save(last_checkpoint, os.path.join(save_dir, 'last_model.pt'))\n",
    "    \n",
    "    # 100 에폭마다 학습 진행 그래프 생성 및 저장\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        try:\n",
    "            print(f\"\\n📊 Epoch {epoch+1} - 학습 진행 상황 그래프 생성 중...\")\n",
    "            plot_training_progress(train_losses, val_maps, val_precisions, val_recalls, val_map50s, epoch+1, save_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"그래프 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 개선된 검증 이미지 시각화 (매 10 에폭마다) - 실제 라벨과 예측 라벨을 별도 figure로 표시\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        try:\n",
    "            # 여러 샘플에 대해 시각화\n",
    "            num_samples = 1 # 샘플 수를 1개\n",
    "            for sample_idx in range(num_samples):\n",
    "                print(f\"\\n📊 Epoch {epoch+1} - 검증 샘플 {sample_idx+1}/{num_samples}:\")\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                # 실제 라벨과 예측 라벨을 별도 figure로 표시\n",
    "                sample_idx = random.randint(0, len(val_dataset)-1)\n",
    "                visualize_ground_truth_and_prediction_separately(\n",
    "                    model, val_dataset, idx=sample_idx, \n",
    "                    epoch=epoch+1, save_dir=save_dir\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"시각화 중 오류: {e}\")\n",
    "\n",
    "print(\"🎯 학습 완료!\")\n",
    "print(f\"최종 베스트 mAP: {best_map:.4f}\")\n",
    "print(f\"모델 저장 위치: {save_dir}\")\n",
    "print(f\"베스트 모델: {os.path.join(save_dir, 'best_model.pt')}\")\n",
    "print(f\"최신 모델: {os.path.join(save_dir, 'last_model.pt')}\")\n",
    "\n",
    "# 최종 성능 요약\n",
    "if val_kappas:\n",
    "    final_kappa = val_kappas[-1]\n",
    "    final_map = val_maps[-1]\n",
    "    final_precision = val_precisions[-1]\n",
    "    final_recall = val_recalls[-1]\n",
    "    final_f1 = 2 * (final_precision * final_recall) / (final_precision + final_recall) if (final_precision + final_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 최종 성능 요약:\")\n",
    "    print(f\"  mAP@0.5:0.95: {final_map:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {final_kappa:.4f} ({get_kappa_interpretation(final_kappa)})\")\n",
    "    print(f\"  F1-score: {final_f1:.4f}\")\n",
    "    print(f\"  Precision: {final_precision:.4f}\")\n",
    "    print(f\"  Recall: {final_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
